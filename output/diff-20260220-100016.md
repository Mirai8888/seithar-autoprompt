# Autoprompt Report
**20260220-100016** | Papers: 126 | Suggestions: 60

## Papers

### [13] Can Adversarial Code Comments Fool AI Security Reviewers -- Large-Scale Empirical Study of Comment-B
Keywords: +adversarial, +manipulation, +deception, vulnerability
Link: https://arxiv.org/abs/2602.16741

### [13] Discrete optimal transport is a strong audio adversarial attack
Keywords: +adversarial attack, +adversarial, alignment
Link: https://arxiv.org/abs/2509.14959

### [12] A feature-stable and explainable machine learning framework for trustworthy decision-making under in
Keywords: +decision-making, +trust
Link: https://arxiv.org/abs/2602.17364

### [11] SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation
Keywords: +reinforcement learning, +manipulation, zero-shot
Link: https://arxiv.org/abs/2602.16863

### [11] The Vulnerability of LLM Rankers to Prompt Injection Attacks
Keywords: +prompt injection, +jailbreak, vulnerability
Link: https://arxiv.org/abs/2602.16752

### [11] A testable framework for AI alignment: Simulation Theology as an engineered worldview for silicon-ba
Keywords: +reinforcement learning, +deception, alignment, RLHF, behavioral, belief
Link: https://arxiv.org/abs/2602.16987

### [10] IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages
Keywords: +jailbreak, +adversarial, alignment
Link: https://arxiv.org/abs/2602.16832

### [10] DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs
Keywords: +jailbreak, +adversarial, guardrail
Link: https://arxiv.org/abs/2602.16935

### [10] The Bots of Persuasion: Examining How Conversational Agents' Linguistic Expressions of Personality A
Keywords: +trust, +manipulation, persona, persuasion
Link: https://arxiv.org/abs/2602.17185

### [9] Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Frame
Keywords: +decision-making, +trust
Link: https://arxiv.org/abs/2602.17106

### [9] Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight
Keywords: +decision-making, +cognitive security, persona, behavioral
Link: https://arxiv.org/abs/2602.17222

### [9] Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning
Keywords: +decision-making, +reinforcement learning
Link: https://arxiv.org/abs/2601.07463

### [9] Self-Improving Skill Learning for Robust Skill-based Meta-Reinforcement Learning
Keywords: +decision-making, +reinforcement learning
Link: https://arxiv.org/abs/2502.03752

### [9] Fault Tolerant Multi-Agent Learning with Adversarial Budget Constraints
Keywords: +adversarial, +reinforcement learning
Link: https://arxiv.org/abs/2508.08800

### [8] Astra: AI Safety, Trust, & Risk Assessment
Keywords: +trust, narrative, guardrail
Link: https://arxiv.org/abs/2602.17357

### [7] Multi-Objective Alignment of Language Models for Personalized Psychotherapy
Keywords: +trust, alignment, persona
Link: https://arxiv.org/abs/2602.16053

### [7] Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting
Keywords: +adversarial attack, +adversarial, alignment
Link: https://arxiv.org/abs/2602.17645

### [7] Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge
Keywords: +adversarial, +trust, guardrail
Link: https://arxiv.org/abs/2602.17452

### [7] MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation
Keywords: +manipulation, zero-shot
Link: https://arxiv.org/abs/2602.11337

### [6] PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarit
Keywords: +reinforcement learning
Link: https://arxiv.org/abs/2510.04080

## Suggested Prompt Updates

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Discrete optimal transport is a strong audio adversarial att' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Discrete optimal transport is a strong audio adversarial attack](https://arxiv.org/abs/2509.14959) (score: 13)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Discrete optimal transport is a strong audio adversarial att' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Discrete optimal transport is a strong audio adversarial attack](https://arxiv.org/abs/2509.14959) (score: 13)

---

### injection_defense -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'The Vulnerability of LLM Rankers to Prompt Injection Attacks' covers prompt injection vectors. Audit [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for injection surface.

Source: [The Vulnerability of LLM Rankers to Prompt Injection Attacks](https://arxiv.org/abs/2602.16752) (score: 11)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'The Vulnerability of LLM Rankers to Prompt Injection Attacks' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [The Vulnerability of LLM Rankers to Prompt Injection Attacks](https://arxiv.org/abs/2602.16752) (score: 11)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'A testable framework for AI alignment: Simulation Theology a' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [A testable framework for AI alignment: Simulation Theology as an engineered worl](https://arxiv.org/abs/2602.16987) (score: 11)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'A testable framework for AI alignment: Simulation Theology a' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [A testable framework for AI alignment: Simulation Theology as an engineered worl](https://arxiv.org/abs/2602.16987) (score: 11)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in S' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832) (score: 10)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in S' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832) (score: 10)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in S' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages](https://arxiv.org/abs/2602.16832) (score: 10)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'DeepContext: Stateful Real-Time Detection of Multi-Turn Adve' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift](https://arxiv.org/abs/2602.16935) (score: 10)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Multi-Objective Alignment of Language Models for Personalize' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053) (score: 7)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Multi-Objective Alignment of Language Models for Personalize' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053) (score: 7)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grai' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting](https://arxiv.org/abs/2602.17645) (score: 7)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grai' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting](https://arxiv.org/abs/2602.17645) (score: 7)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Fail-Closed Alignment for Large Language Models' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Fail-Closed Alignment for Large Language Models' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Fail-Closed Alignment for Large Language Models' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'References Improve LLM Alignment in Non-Verifiable Domains' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [References Improve LLM Alignment in Non-Verifiable Domains](https://arxiv.org/abs/2602.16802) (score: 5)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'References Improve LLM Alignment in Non-Verifiable Domains' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [References Improve LLM Alignment in Non-Verifiable Domains](https://arxiv.org/abs/2602.16802) (score: 5)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dia' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation ](https://arxiv.org/abs/2602.17469) (score: 5)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dia' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation ](https://arxiv.org/abs/2602.17469) (score: 5)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'The Subjectivity of Respect in Police Traffic Stops: Modelin' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspect](https://arxiv.org/abs/2602.10339) (score: 5)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'The Subjectivity of Respect in Police Traffic Stops: Modelin' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspect](https://arxiv.org/abs/2602.10339) (score: 5)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Mind the GAP: Text Safety Does Not Transfer to Tool-Call Saf' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](https://arxiv.org/abs/2602.16943) (score: 5)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Mind the GAP: Text Safety Does Not Transfer to Tool-Call Saf' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](https://arxiv.org/abs/2602.16943) (score: 5)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Mind the GAP: Text Safety Does Not Transfer to Tool-Call Saf' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents](https://arxiv.org/abs/2602.16943) (score: 5)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'The Emergence of Lab-Driven Alignment Signatures: A Psychome' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for A](https://arxiv.org/abs/2602.17127) (score: 4)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'The Emergence of Lab-Driven Alignment Signatures: A Psychome' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for A](https://arxiv.org/abs/2602.17127) (score: 4)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Proof-RM: A Scalable and Generalizable Reward Model for Math' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Proof-RM: A Scalable and Generalizable Reward Model for Math Proof](https://arxiv.org/abs/2602.02377) (score: 4)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Proof-RM: A Scalable and Generalizable Reward Model for Math' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Proof-RM: A Scalable and Generalizable Reward Model for Math Proof](https://arxiv.org/abs/2602.02377) (score: 4)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Helpful to a Fault: Measuring Illicit Assistance in Multi-Tu' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM](https://arxiv.org/abs/2602.16346) (score: 4)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Auditing Student-AI Collaboration: A Case Study of Online Gr' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697) (score: 4)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Auditing Student-AI Collaboration: A Case Study of Online Gr' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697) (score: 4)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Intent Laundering: AI Safety Datasets Are Not What They Seem' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [Intent Laundering: AI Safety Datasets Are Not What They Seem](https://arxiv.org/abs/2602.16729) (score: 3)

---

### injection_defense -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Policy Compiler for Secure Agentic Systems' covers prompt injection vectors. Audit [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for injection surface.

Source: [Policy Compiler for Secure Agentic Systems](https://arxiv.org/abs/2602.16708) (score: 3)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'NeST: Neuron Selective Tuning for LLM Safety' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835) (score: 3)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'NeST: Neuron Selective Tuning for LLM Safety' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835) (score: 3)

---

### injection_defense -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Systems Security Foundations for Agentic Computing' covers prompt injection vectors. Audit [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for injection surface.

Source: [Systems Security Foundations for Agentic Computing](https://arxiv.org/abs/2512.01295) (score: 3)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Preserving Historical Truth: Detecting Historical Revisionis' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Preserving Historical Truth: Detecting Historical Revisionism in Large Language ](https://arxiv.org/abs/2602.17433) (score: 3)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Preserving Historical Truth: Detecting Historical Revisionis' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Preserving Historical Truth: Detecting Historical Revisionism in Large Language ](https://arxiv.org/abs/2602.17433) (score: 3)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Tu](https://arxiv.org/abs/2602.16957) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Tu](https://arxiv.org/abs/2602.16957) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Differences in Typological Alignment in Language Models' Tre' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Differences in Typological Alignment in Language Models' Treatment of Differenti](https://arxiv.org/abs/2602.17653) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Differences in Typological Alignment in Language Models' Tre' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Differences in Typological Alignment in Language Models' Treatment of Differenti](https://arxiv.org/abs/2602.17653) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Narrow fine-tuning erodes safety alignment in vision-languag' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Narrow fine-tuning erodes safety alignment in vision-languag' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Conv-FinRe: A Conversational and Longitudinal Benchmark for ' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Fin](https://arxiv.org/abs/2602.16990) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Conv-FinRe: A Conversational and Longitudinal Benchmark for ' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Fin](https://arxiv.org/abs/2602.16990) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'ODESteer: A Unified ODE-Based Steering Framework for LLM Ali' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'ODESteer: A Unified ODE-Based Steering Framework for LLM Ali' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'HiVAE: Hierarchical Latent Variables for Scalable Theory of ' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'HiVAE: Hierarchical Latent Variables for Scalable Theory of ' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignmen](https://arxiv.org/abs/2602.17095) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignmen](https://arxiv.org/abs/2602.17095) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Federated Latent Space Alignment for Multi-user Semantic Com' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Federated Latent Space Alignment for Multi-user Semantic Communications](https://arxiv.org/abs/2602.17271) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Federated Latent Space Alignment for Multi-user Semantic Com' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Federated Latent Space Alignment for Multi-user Semantic Communications](https://arxiv.org/abs/2602.17271) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'MARS: Margin-Aware Reward-Modeling with Self-Refinement' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [MARS: Margin-Aware Reward-Modeling with Self-Refinement](https://arxiv.org/abs/2602.17658) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'MARS: Margin-Aware Reward-Modeling with Self-Refinement' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [MARS: Margin-Aware Reward-Modeling with Self-Refinement](https://arxiv.org/abs/2602.17658) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Improved Object-Centric Diffusion Learning with Registers an' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignm](https://arxiv.org/abs/2601.01224) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Improved Object-Centric Diffusion Learning with Registers an' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignm](https://arxiv.org/abs/2601.01224) (score: 2)

---

