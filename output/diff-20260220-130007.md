# Autoprompt Report
**20260220-130007** | Papers: 38 | Suggestions: 16

## Papers

### [10] DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs
Keywords: +jailbreak, +adversarial, guardrail
Link: https://arxiv.org/abs/2602.16935

### [7] Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge
Keywords: +adversarial, +trust, guardrail
Link: https://arxiv.org/abs/2602.17452

### [6] Automating Agent Hijacking via Structural Template Injection
Keywords: +adversarial, +manipulation
Link: https://arxiv.org/abs/2602.16958

### [6] Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance
Keywords: +reinforcement learning
Link: https://arxiv.org/abs/2602.17098

### [6] Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning
Keywords: +reinforcement learning
Link: https://arxiv.org/abs/2506.21039

### [6] Fail-Closed Alignment for Large Language Models
Keywords: +jailbreak, alignment, LLM safety
Link: https://arxiv.org/abs/2602.16977

### [5] Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to
Keywords: +decision-making, zero-shot
Link: https://arxiv.org/abs/2602.17513

### [4] ReIn: Conversational Error Recovery with Reasoning Inception
Keywords: +decision-making, system prompt
Link: https://arxiv.org/abs/2602.17022

### [4] A Unified Framework for Locality in Scalable MARL
Keywords: +reinforcement learning, exploit
Link: https://arxiv.org/abs/2602.16966

### [4] Capturing Individual Human Preferences with Reward Features
Keywords: +reinforcement learning, persona
Link: https://arxiv.org/abs/2503.17338

### [4] CareerPooler: AI-Powered Metaphorical Pool Simulation Improves Experience and Outcomes in Career Exp
Keywords: +decision-making, narrative
Link: https://arxiv.org/abs/2509.11461

### [4] Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students
Keywords: +trust, alignment
Link: https://arxiv.org/abs/2601.08697

### [4] Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis
Keywords: +adversarial, narrative
Link: https://arxiv.org/abs/2602.15909

### [3] RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Rea
Keywords: +trust
Link: https://arxiv.org/abs/2602.17053

### [3] DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing
Keywords: +adversarial
Link: https://arxiv.org/abs/2602.17413

### [3] Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models
Keywords: persona, zero-shot
Link: https://arxiv.org/abs/2506.11798

### [3] Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Fea
Keywords: +trust
Link: https://arxiv.org/abs/2512.11108

### [3] $\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts
Keywords: +reinforcement learning
Link: https://arxiv.org/abs/2506.15733

### [3] Bridging Symbolic Control and Neural Reasoning in LLM Agents: Structured Cognitive Loop with a Gover
Keywords: +trust
Link: https://arxiv.org/abs/2511.17673

### [3] Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI
Keywords: +trust
Link: https://arxiv.org/abs/2602.16814

## Suggested Prompt Updates

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'DeepContext: Stateful Real-Time Detection of Multi-Turn Adve' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift](https://arxiv.org/abs/2602.16935) (score: 10)

---

### defense_hardening -> `autoprompt-digest-2026-02-20.md` / ### 6. Large Behavioral Model for Strategic Prediction (Score: 9)

> Paper 'DeepContext: Stateful Real-Time Detection of Multi-Turn Adve' describes new jailbreak techniques. Review defensive constraints in [### 6. Large Behavioral Model for Strategic Prediction (Score: 9)] for gaps.

Source: [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift](https://arxiv.org/abs/2602.16935) (score: 10)

---

### defense_hardening -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Fail-Closed Alignment for Large Language Models' describes new jailbreak techniques. Review defensive constraints in [### 1. Robust Deep RL against Adversarial Behavior Manipulation] for gaps.

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### defense_hardening -> `autoprompt-digest-2026-02-20.md` / ### 6. Large Behavioral Model for Strategic Prediction (Score: 9)

> Paper 'Fail-Closed Alignment for Large Language Models' describes new jailbreak techniques. Review defensive constraints in [### 6. Large Behavioral Model for Strategic Prediction (Score: 9)] for gaps.

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Fail-Closed Alignment for Large Language Models' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `autoprompt-digest-2026-02-20.md` / ## Priority Papers (Score 7+)

> Paper 'Fail-Closed Alignment for Large Language Models' has findings on alignment. Review behavioral alignment in [## Priority Papers (Score 7+)].

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Fail-Closed Alignment for Large Language Models' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977) (score: 6)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'Auditing Student-AI Collaboration: A Case Study of Online Gr' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697) (score: 4)

---

### alignment_update -> `autoprompt-digest-2026-02-20.md` / ## Priority Papers (Score 7+)

> Paper 'Auditing Student-AI Collaboration: A Case Study of Online Gr' has findings on alignment. Review behavioral alignment in [## Priority Papers (Score 7+)].

Source: [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697) (score: 4)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'Auditing Student-AI Collaboration: A Case Study of Online Gr' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students](https://arxiv.org/abs/2601.08697) (score: 4)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'NeST: Neuron Selective Tuning for LLM Safety' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835) (score: 3)

---

### alignment_update -> `autoprompt-digest-2026-02-20.md` / ## Priority Papers (Score 7+)

> Paper 'NeST: Neuron Selective Tuning for LLM Safety' has findings on alignment. Review behavioral alignment in [## Priority Papers (Score 7+)].

Source: [NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835) (score: 3)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'NeST: Neuron Selective Tuning for LLM Safety' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [NeST: Neuron Selective Tuning for LLM Safety](https://arxiv.org/abs/2602.16835) (score: 3)

---

### alignment_update -> `autoprompt-digest-2026-02-19.md` / ### 1. Robust Deep RL against Adversarial Behavior Manipulation

> Paper 'ODESteer: A Unified ODE-Based Steering Framework for LLM Ali' has findings on alignment. Review behavioral alignment in [### 1. Robust Deep RL against Adversarial Behavior Manipulation].

Source: [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560) (score: 2)

---

### alignment_update -> `autoprompt-digest-2026-02-20.md` / ## Priority Papers (Score 7+)

> Paper 'ODESteer: A Unified ODE-Based Steering Framework for LLM Ali' has findings on alignment. Review behavioral alignment in [## Priority Papers (Score 7+)].

Source: [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560) (score: 2)

---

### alignment_update -> `DESIGN_SYSTEM_REFACTOR.md` / ## Core framing (system prompt)

> Paper 'ODESteer: A Unified ODE-Based Steering Framework for LLM Ali' has findings on alignment. Review behavioral alignment in [## Core framing (system prompt)].

Source: [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560) (score: 2)

---

